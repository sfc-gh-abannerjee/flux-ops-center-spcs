{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux Ops Center - SPCS Deployment Notebook\n",
    "\n",
    "**Purpose**: Deploy Flux Operations Center SPCS infrastructure using Snowflake Notebooks\n",
    "\n",
    "This notebook deploys:\n",
    "- Image repository for Docker containers\n",
    "- Compute pool for SPCS service\n",
    "- SPCS service with proper configuration\n",
    "- Snowflake Postgres instance (optional)\n",
    "\n",
    "**Prerequisites**:\n",
    "1. flux-utility-solutions deployed (creates database, schemas, tables)\n",
    "2. Docker image built and pushed to registry\n",
    "\n",
    "**Estimated Time**: 10-15 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your deployment parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these values for your environment\n",
    "# =============================================================================\n",
    "\n",
    "# Target database (must exist - deploy flux-utility-solutions first)\n",
    "DATABASE = \"FLUX_DB\"\n",
    "SCHEMA = \"PUBLIC\"\n",
    "WAREHOUSE = \"FLUX_WH\"\n",
    "\n",
    "# SPCS Configuration\n",
    "IMAGE_REPO = \"FLUX_OPS_CENTER_IMAGES\"\n",
    "COMPUTE_POOL = \"FLUX_OPS_CENTER_POOL\"\n",
    "SERVICE_NAME = \"FLUX_OPS_CENTER_SERVICE\"\n",
    "IMAGE_TAG = \"latest\"\n",
    "\n",
    "# Compute pool sizing\n",
    "INSTANCE_FAMILY = \"CPU_X64_S\"  # Options: CPU_X64_XS, CPU_X64_S, CPU_X64_M, CPU_X64_L\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 2\n",
    "\n",
    "# Postgres Configuration (for map visualization)\n",
    "POSTGRES_INSTANCE = \"FLUX_OPS_POSTGRES\"\n",
    "POSTGRES_HOST = \"\"  # Will be populated after creation\n",
    "\n",
    "print(f\"Target Database: {DATABASE}\")\n",
    "print(f\"Service Name: {SERVICE_NAME}\")\n",
    "print(f\"Compute Pool: {COMPUTE_POOL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Snowflake session\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# Verify connection\n",
    "result = session.sql(\"SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_ACCOUNT()\").collect()\n",
    "print(f\"User: {result[0][0]}\")\n",
    "print(f\"Role: {result[0][1]}\")\n",
    "print(f\"Account: {result[0][2]}\")\n",
    "\n",
    "# Set context\n",
    "session.sql(f\"USE DATABASE {DATABASE}\").collect()\n",
    "session.sql(f\"USE SCHEMA {SCHEMA}\").collect()\n",
    "session.sql(f\"USE WAREHOUSE {WAREHOUSE}\").collect()\n",
    "print(f\"\\nContext set to: {DATABASE}.{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Verify Prerequisites\n",
    "\n",
    "Check that flux-utility-solutions has been deployed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify required schemas exist (from flux-utility-solutions)\n",
    "required_schemas = ['PRODUCTION', 'APPLICATIONS', 'ML_DEMO', 'CASCADE_ANALYSIS']\n",
    "\n",
    "existing_schemas = session.sql(f\"\"\"\n",
    "    SELECT SCHEMA_NAME \n",
    "    FROM {DATABASE}.INFORMATION_SCHEMA.SCHEMATA\n",
    "    WHERE SCHEMA_NAME IN ({','.join([f\"'{s}'\" for s in required_schemas])})\n",
    "\"\"\").collect()\n",
    "\n",
    "existing = [row[0] for row in existing_schemas]\n",
    "missing = [s for s in required_schemas if s not in existing]\n",
    "\n",
    "print(\"PREREQUISITE CHECK\")\n",
    "print(\"=\" * 50)\n",
    "for schema in required_schemas:\n",
    "    status = \"✓\" if schema in existing else \"✗ MISSING\"\n",
    "    print(f\"  {status} {schema}\")\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\n⚠️  Missing schemas: {missing}\")\n",
    "    print(\"   Deploy flux-utility-solutions first, or use standalone quickstart:\")\n",
    "    print(\"   snow sql -f scripts/sql/00_standalone_quickstart.sql\")\n",
    "else:\n",
    "    print(f\"\\n✓ All prerequisites met - ready to deploy SPCS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Create Image Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image repository\n",
    "session.sql(f\"\"\"\n",
    "    CREATE IMAGE REPOSITORY IF NOT EXISTS {IMAGE_REPO}\n",
    "    COMMENT = 'Image repository for Flux Operations Center containers'\n",
    "\"\"\").collect()\n",
    "\n",
    "# Get repository URL for Docker push\n",
    "repo_info = session.sql(f\"SHOW IMAGE REPOSITORIES LIKE '{IMAGE_REPO}'\").collect()\n",
    "if repo_info:\n",
    "    repo_url = repo_info[0]['repository_url']\n",
    "    print(f\"✓ Image Repository: {IMAGE_REPO}\")\n",
    "    print(f\"\\nDocker Push Commands:\")\n",
    "    print(f\"  docker login {repo_url.split('/')[0]}\")\n",
    "    print(f\"  docker build -t flux-ops-center:{IMAGE_TAG} -f Dockerfile.spcs .\")\n",
    "    print(f\"  docker tag flux-ops-center:{IMAGE_TAG} {repo_url}/flux_ops_center:{IMAGE_TAG}\")\n",
    "    print(f\"  docker push {repo_url}/flux_ops_center:{IMAGE_TAG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Create Compute Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compute pool\n",
    "session.sql(f\"\"\"\n",
    "    CREATE COMPUTE POOL IF NOT EXISTS {COMPUTE_POOL}\n",
    "    MIN_NODES = {MIN_NODES}\n",
    "    MAX_NODES = {MAX_NODES}\n",
    "    INSTANCE_FAMILY = {INSTANCE_FAMILY}\n",
    "    AUTO_RESUME = TRUE\n",
    "    AUTO_SUSPEND_SECS = 300\n",
    "    COMMENT = 'Compute pool for Flux Operations Center'\n",
    "\"\"\").collect()\n",
    "\n",
    "# Check status\n",
    "pool_info = session.sql(f\"DESCRIBE COMPUTE POOL {COMPUTE_POOL}\").collect()\n",
    "print(f\"✓ Compute Pool: {COMPUTE_POOL}\")\n",
    "print(f\"  Instance Family: {INSTANCE_FAMILY}\")\n",
    "print(f\"  Min/Max Nodes: {MIN_NODES}/{MAX_NODES}\")\n",
    "print(f\"  Status: {pool_info[0]['state'] if pool_info else 'CREATED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Set Up Snowflake Postgres (Optional)\n",
    "\n",
    "Required for map visualization with PostGIS spatial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Postgres instance already exists\n",
    "existing_pg = session.sql(f\"SHOW POSTGRES INSTANCES LIKE '{POSTGRES_INSTANCE}'\").collect()\n",
    "\n",
    "if existing_pg:\n",
    "    POSTGRES_HOST = existing_pg[0]['host']\n",
    "    print(f\"✓ Postgres Instance exists: {POSTGRES_INSTANCE}\")\n",
    "    print(f\"  Host: {POSTGRES_HOST}\")\n",
    "else:\n",
    "    print(f\"Postgres instance '{POSTGRES_INSTANCE}' not found.\")\n",
    "    print(\"\\nTo create one, run:\")\n",
    "    print(f\"\"\"\n",
    "CREATE POSTGRES DATABASE {POSTGRES_INSTANCE}\n",
    "    POSTGRES_ADMIN_PASSWORD = 'YourSecurePassword123!'\n",
    "    AUTO_SUSPEND_MINS = 30\n",
    "    COMPUTE_SIZE = 'HIGHMEM_XL'\n",
    "    STORAGE_SIZE_GB = 100;\n",
    "\"\"\")\n",
    "    print(\"\\nThen run: SHOW POSTGRES INSTANCES LIKE 'FLUX_OPS_POSTGRES';\")\n",
    "    print(\"Copy the 'host' value and update POSTGRES_HOST variable above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Create SPCS Service\n",
    "\n",
    "**Important**: Ensure Docker image is pushed before running this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Postgres host is set\n",
    "if not POSTGRES_HOST:\n",
    "    print(\"⚠️  POSTGRES_HOST not set. Map visualization will not work.\")\n",
    "    print(\"   Set POSTGRES_HOST variable or create a Postgres instance first.\")\n",
    "    POSTGRES_HOST = \"placeholder.postgres.snowflake.app\"  # Will fail at runtime\n",
    "\n",
    "# Create service specification\n",
    "service_spec = f\"\"\"\n",
    "spec:\n",
    "  containers:\n",
    "    - name: flux-ops-center\n",
    "      image: /{DATABASE}/{SCHEMA}/{IMAGE_REPO}/flux_ops_center:{IMAGE_TAG}\n",
    "      env:\n",
    "        SNOWFLAKE_DATABASE: {DATABASE}\n",
    "        SNOWFLAKE_WAREHOUSE: {WAREHOUSE}\n",
    "        SNOWFLAKE_SCHEMA: PRODUCTION\n",
    "        APPLICATIONS_SCHEMA: APPLICATIONS\n",
    "        ML_SCHEMA: ML_DEMO\n",
    "        CASCADE_SCHEMA: CASCADE_ANALYSIS\n",
    "        VITE_POSTGRES_HOST: {POSTGRES_HOST}\n",
    "        VITE_POSTGRES_PORT: \"5432\"\n",
    "        VITE_POSTGRES_DATABASE: postgres\n",
    "      resources:\n",
    "        requests:\n",
    "          cpu: 2\n",
    "          memory: 4Gi\n",
    "        limits:\n",
    "          cpu: 4\n",
    "          memory: 8Gi\n",
    "  endpoints:\n",
    "    - name: app\n",
    "      port: 8080\n",
    "      public: true\n",
    "\"\"\"\n",
    "\n",
    "print(\"Service Specification:\")\n",
    "print(service_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SPCS service\n",
    "# Note: This will fail if Docker image hasn't been pushed yet\n",
    "\n",
    "try:\n",
    "    session.sql(f\"\"\"\n",
    "        CREATE SERVICE IF NOT EXISTS {SERVICE_NAME}\n",
    "        IN COMPUTE POOL {COMPUTE_POOL}\n",
    "        FROM SPECIFICATION $${service_spec}$$\n",
    "        QUERY_WAREHOUSE = {WAREHOUSE}\n",
    "        COMMENT = 'Flux Operations Center - Grid Visualization & GNN Risk Prediction'\n",
    "    \"\"\").collect()\n",
    "    \n",
    "    # Grant public access\n",
    "    session.sql(f\"GRANT USAGE ON SERVICE {SERVICE_NAME} TO ROLE PUBLIC\").collect()\n",
    "    \n",
    "    print(f\"✓ Service created: {SERVICE_NAME}\")\n",
    "    print(\"\\nService is starting... This may take 2-5 minutes.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    if \"does not exist\" in str(e).lower() and \"image\" in str(e).lower():\n",
    "        print(\"✗ Docker image not found in repository!\")\n",
    "        print(\"\\nPush the image first:\")\n",
    "        print(f\"  docker push {repo_url}/flux_ops_center:{IMAGE_TAG}\")\n",
    "    else:\n",
    "        print(f\"Error creating service: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6: Verify Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check service status\n",
    "import json\n",
    "\n",
    "try:\n",
    "    status_json = session.sql(f\"SELECT SYSTEM$GET_SERVICE_STATUS('{SERVICE_NAME}')\").collect()[0][0]\n",
    "    status = json.loads(status_json)\n",
    "    \n",
    "    print(\"SERVICE STATUS\")\n",
    "    print(\"=\" * 50)\n",
    "    for container in status:\n",
    "        print(f\"  Container: {container.get('containerName', 'unknown')}\")\n",
    "        print(f\"  Status: {container.get('status', 'unknown')}\")\n",
    "        print(f\"  Message: {container.get('message', 'none')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Service not ready yet: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get service endpoint URL\n",
    "try:\n",
    "    endpoints = session.sql(f\"SHOW ENDPOINTS IN SERVICE {SERVICE_NAME}\").collect()\n",
    "    \n",
    "    print(\"SERVICE ENDPOINTS\")\n",
    "    print(\"=\" * 50)\n",
    "    for ep in endpoints:\n",
    "        print(f\"  Endpoint: {ep['name']}\")\n",
    "        print(f\"  URL: {ep['ingress_url']}\")\n",
    "        print(f\"\\n✓ Flux Ops Center is ready!\")\n",
    "        print(f\"  Open: {ep['ingress_url']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Endpoints not available yet: {e}\")\n",
    "    print(\"\\nWait 2-5 minutes for service to start, then run this cell again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### Required: Load PostGIS Spatial Data\n",
    "\n",
    "**Without this step, the map will not display any data.**\n",
    "\n",
    "```bash\n",
    "# From your local machine:\n",
    "python backend/scripts/load_postgis_data.py --service FLUX_OPS_POSTGRES\n",
    "```\n",
    "\n",
    "### Optional: Populate Cascade Analysis Tables\n",
    "\n",
    "```bash\n",
    "# Step 1: Compute graph centrality metrics\n",
    "python backend/scripts/compute_graph_centrality.py\n",
    "\n",
    "# Step 2: Pre-compute cascade scenarios  \n",
    "python backend/scripts/cascade_simulator.py --scenarios 100\n",
    "\n",
    "# Step 3: Train GNN model\n",
    "python backend/scripts/train_gnn_model.py\n",
    "```\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "```sql\n",
    "-- View service logs\n",
    "CALL SYSTEM$GET_SERVICE_LOGS('FLUX_OPS_CENTER_SERVICE', '0', 'flux-ops-center', 100);\n",
    "\n",
    "-- Restart service\n",
    "ALTER SERVICE FLUX_OPS_CENTER_SERVICE SUSPEND;\n",
    "ALTER SERVICE FLUX_OPS_CENTER_SERVICE RESUME;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
