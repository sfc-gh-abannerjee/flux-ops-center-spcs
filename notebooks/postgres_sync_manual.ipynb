{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowflake to Postgres Manual Sync\n",
    "\n",
    "This notebook provides manual control over syncing data from Snowflake to Snowflake Managed Postgres.\n",
    "\n",
    "## Architecture\n",
    "- **Snowflake**: Source of truth for all grid data\n",
    "- **Postgres**: PostGIS cache for fast spatial queries (<20ms vs seconds)\n",
    "- **Sync Strategy**: Full refresh (TRUNCATE + INSERT) - idempotent and recoverable\n",
    "\n",
    "## Layer Mapping\n",
    "\n",
    "| Layer | Snowflake Source | Postgres Target | Rows |\n",
    "|-------|------------------|-----------------|------|\n",
    "| Meters | METER_INFRASTRUCTURE | meters_spatial | 596,906 |\n",
    "| Substations | SUBSTATIONS | substations_spatial | 275 |\n",
    "| Transformers | TRANSFORMER_METADATA | transformers_spatial | 91,554 |\n",
    "| Power Lines | GRID_POWER_LINES | power_lines_lod | 13,104 |\n",
    "| Poles | OSM_POLES_TRULY_LAND_ONLY | poles_spatial | 62,735 |\n",
    "| Buildings | HOUSTON_BUILDINGS_CLEAN | osm_buildings | 2,670,794 |\n",
    "| Water Bodies | HOUSTON_WATER_BODIES | osm_water | 10,000 |\n",
    "| Vegetation | VEGETATION_POWER_LINE_RISK | vegetation_risk_cache | 3,611 |"
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - UPDATE THESE VALUES\n",
    "CONFIG = {\n",
    "    # Snowflake\n",
    "    'snowflake_connection': 'cpe_demo_CLI',  # Your Snowflake connection name\n",
    "    'database': 'FLUX_DB',\n",
    "    'schema': 'PRODUCTION',\n",
    "    'warehouse': 'FLUX_WH',\n",
    "    \n",
    "    # Postgres (Snowflake Managed)\n",
    "    'pg_host': 'YOUR_POSTGRES_HOST.snowflakecomputing.app',  # From SHOW POSTGRES INSTANCES\n",
    "    'pg_port': 5432,\n",
    "    'pg_database': 'postgres',\n",
    "    'pg_user': 'application',\n",
    "    'pg_password': 'YOUR_PASSWORD',  # From CREATE USER command\n",
    "    \n",
    "    # Sync settings\n",
    "    'batch_size': 10000,  # For large tables\n",
    "    'verbose': True\n",
    "}"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Connections"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Snowflake connection\n",
    "def get_snowflake_conn():\n",
    "    return snowflake.connector.connect(\n",
    "        connection_name=CONFIG['snowflake_connection'],\n",
    "        database=CONFIG['database'],\n",
    "        schema=CONFIG['schema'],\n",
    "        warehouse=CONFIG['warehouse']\n",
    "    )\n",
    "\n",
    "# Postgres connection\n",
    "def get_postgres_conn():\n",
    "    conn = psycopg2.connect(\n",
    "        host=CONFIG['pg_host'],\n",
    "        port=CONFIG['pg_port'],\n",
    "        database=CONFIG['pg_database'],\n",
    "        user=CONFIG['pg_user'],\n",
    "        password=CONFIG['pg_password']\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    return conn\n",
    "\n",
    "# Test connections\n",
    "print(\"Testing Snowflake connection...\")\n",
    "sf_conn = get_snowflake_conn()\n",
    "print(f\"  Connected to Snowflake: {CONFIG['database']}.{CONFIG['schema']}\")\n",
    "sf_conn.close()\n",
    "\n",
    "print(\"\\nTesting Postgres connection...\")\n",
    "pg_conn = get_postgres_conn()\n",
    "pg_cursor = pg_conn.cursor()\n",
    "pg_cursor.execute(\"SELECT PostGIS_Version();\")\n",
    "print(f\"  Connected to Postgres with PostGIS {pg_cursor.fetchone()[0]}\")\n",
    "pg_conn.close()\n",
    "\n",
    "print(\"\\n✓ All connections successful!\")"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sync Helper Functions"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyncResult:\n",
    "    def __init__(self, layer):\n",
    "        self.layer = layer\n",
    "        self.started = datetime.now()\n",
    "        self.rows = 0\n",
    "        self.status = 'running'\n",
    "        self.error = None\n",
    "    \n",
    "    def complete(self, rows):\n",
    "        self.rows = rows\n",
    "        self.status = 'success'\n",
    "        self.duration = (datetime.now() - self.started).total_seconds()\n",
    "        return self\n",
    "    \n",
    "    def fail(self, error):\n",
    "        self.error = str(error)\n",
    "        self.status = 'failed'\n",
    "        self.duration = (datetime.now() - self.started).total_seconds()\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.status == 'success':\n",
    "            return f\"✓ {self.layer}: {self.rows:,} rows in {self.duration:.1f}s\"\n",
    "        return f\"✗ {self.layer}: FAILED - {self.error}\"\n",
    "\n",
    "\n",
    "def sync_layer(layer_name, sf_query, pg_table, pg_insert_sql, row_mapper):\n",
    "    \"\"\"Generic sync function for any layer.\"\"\"\n",
    "    result = SyncResult(layer_name)\n",
    "    \n",
    "    try:\n",
    "        sf_conn = get_snowflake_conn()\n",
    "        pg_conn = get_postgres_conn()\n",
    "        pg_cursor = pg_conn.cursor()\n",
    "        \n",
    "        if CONFIG['verbose']:\n",
    "            print(f\"Syncing {layer_name}...\")\n",
    "        \n",
    "        # Truncate target\n",
    "        pg_cursor.execute(f'TRUNCATE TABLE {pg_table};')\n",
    "        \n",
    "        # Fetch from Snowflake\n",
    "        sf_cursor = sf_conn.cursor()\n",
    "        sf_cursor.execute(sf_query)\n",
    "        \n",
    "        # Insert in batches\n",
    "        batch = []\n",
    "        count = 0\n",
    "        \n",
    "        for row in sf_cursor:\n",
    "            mapped = row_mapper(row)\n",
    "            if mapped:\n",
    "                batch.append(mapped)\n",
    "            \n",
    "            if len(batch) >= CONFIG['batch_size']:\n",
    "                pg_cursor.executemany(pg_insert_sql, batch)\n",
    "                count += len(batch)\n",
    "                if CONFIG['verbose']:\n",
    "                    print(f\"  ... {count:,} rows\")\n",
    "                batch = []\n",
    "        \n",
    "        if batch:\n",
    "            pg_cursor.executemany(pg_insert_sql, batch)\n",
    "            count += len(batch)\n",
    "        \n",
    "        sf_conn.close()\n",
    "        pg_conn.close()\n",
    "        \n",
    "        return result.complete(count)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return result.fail(e)"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sync Functions for Each Layer"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_meters():\n",
    "    \"\"\"Sync 596K smart meters.\"\"\"\n",
    "    return sync_layer(\n",
    "        layer_name='meters',\n",
    "        sf_query=\"\"\"\n",
    "            SELECT METER_ID, METER_LATITUDE, METER_LONGITUDE, TRANSFORMER_ID, CIRCUIT_ID, \n",
    "                   SUBSTATION_ID, POLE_ID, METER_TYPE, CUSTOMER_SEGMENT_ID, CITY, \n",
    "                   COUNTY_NAME, ZIP_CODE, COMMISSIONED_DATE, HEALTH_SCORE\n",
    "            FROM METER_INFRASTRUCTURE\n",
    "            WHERE METER_LATITUDE IS NOT NULL AND METER_LONGITUDE IS NOT NULL\n",
    "        \"\"\",\n",
    "        pg_table='meters_spatial',\n",
    "        pg_insert_sql=\"\"\"\n",
    "            INSERT INTO meters_spatial \n",
    "            (meter_id, latitude, longitude, transformer_id, circuit_id, substation_id, \n",
    "             pole_id, meter_type, customer_segment, city, county, zip_code, \n",
    "             commissioned_date, health_score, geom)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                    ST_SetSRID(ST_MakePoint(%s, %s), 4326))\n",
    "        \"\"\",\n",
    "        row_mapper=lambda r: (\n",
    "            r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[7], r[8], r[9], r[10], r[11], r[12], r[13],\n",
    "            r[2], r[1]  # lon, lat for geom\n",
    "        )\n",
    "    )\n",
    "\n",
    "def sync_substations():\n",
    "    \"\"\"Sync 275 substations.\"\"\"\n",
    "    return sync_layer(\n",
    "        layer_name='substations',\n",
    "        sf_query=\"\"\"\n",
    "            SELECT SUBSTATION_ID, SUBSTATION_NAME, LATITUDE, LONGITUDE, CAPACITY_MVA,\n",
    "                   CURRENT_LOAD_MW, PEAK_LOAD_MW, VOLTAGE_LEVEL, SUBSTATION_TYPE,\n",
    "                   OPERATIONAL_STATUS, REGION, COMMISSIONED_DATE, LAST_INSPECTION_DATE,\n",
    "                   CRITICAL_INFRASTRUCTURE_FLAG\n",
    "            FROM SUBSTATIONS\n",
    "            WHERE LATITUDE IS NOT NULL AND LONGITUDE IS NOT NULL\n",
    "        \"\"\",\n",
    "        pg_table='substations_spatial',\n",
    "        pg_insert_sql=\"\"\"\n",
    "            INSERT INTO substations_spatial \n",
    "            (substation_id, name, latitude, longitude, capacity_mva, current_load_mw,\n",
    "             peak_load_mw, voltage_level, substation_type, operational_status, region,\n",
    "             commissioned_date, last_inspection_date, critical_infrastructure, geom)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                    ST_SetSRID(ST_MakePoint(%s, %s), 4326))\n",
    "        \"\"\",\n",
    "        row_mapper=lambda r: (\n",
    "            r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[7], r[8], r[9], r[10], r[11], r[12], r[13],\n",
    "            r[3], r[2]  # lon, lat for geom\n",
    "        )\n",
    "    )\n",
    "\n",
    "def sync_transformers():\n",
    "    \"\"\"Sync 91K transformers.\"\"\"\n",
    "    return sync_layer(\n",
    "        layer_name='transformers',\n",
    "        sf_query=\"\"\"\n",
    "            SELECT TRANSFORMER_ID, SUBSTATION_ID, CIRCUIT_ID, LATITUDE, LONGITUDE,\n",
    "                   RATED_KVA, CURRENT_LOAD_KVA, LOAD_UTILIZATION_PCT, AGE_YEARS, HEALTH_SCORE,\n",
    "                   MANUFACTURER, MODEL_NUMBER, INSTALL_YEAR, LAST_MAINTENANCE_DATE,\n",
    "                   TRANSFORMER_ROLE, PHASE_CODE, PRIMARY_VOLTAGE_KV\n",
    "            FROM TRANSFORMER_METADATA\n",
    "            WHERE LATITUDE IS NOT NULL AND LONGITUDE IS NOT NULL\n",
    "        \"\"\",\n",
    "        pg_table='transformers_spatial',\n",
    "        pg_insert_sql=\"\"\"\n",
    "            INSERT INTO transformers_spatial \n",
    "            (transformer_id, substation_id, circuit_id, latitude, longitude, rated_kva,\n",
    "             current_load_kva, load_utilization_pct, age_years, health_score, manufacturer,\n",
    "             model_number, install_year, last_maintenance, transformer_role, phase_code,\n",
    "             primary_voltage_kv, geom)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                    ST_SetSRID(ST_MakePoint(%s, %s), 4326))\n",
    "        \"\"\",\n",
    "        row_mapper=lambda r: (\n",
    "            r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[7], r[8], r[9], r[10], r[11], r[12], r[13], r[14], r[15], r[16],\n",
    "            r[4], r[3]  # lon, lat for geom\n",
    "        )\n",
    "    )\n",
    "\n",
    "def sync_poles():\n",
    "    \"\"\"Sync 62K utility poles.\"\"\"\n",
    "    return sync_layer(\n",
    "        layer_name='poles',\n",
    "        sf_query=\"\"\"\n",
    "            SELECT OSM_POLE_ID, OSM_LAT, OSM_LON, POWER_TYPE, VOLTAGE\n",
    "            FROM OSM_POLES_TRULY_LAND_ONLY\n",
    "            WHERE OSM_LAT IS NOT NULL AND OSM_LON IS NOT NULL\n",
    "        \"\"\",\n",
    "        pg_table='poles_spatial',\n",
    "        pg_insert_sql=\"\"\"\n",
    "            INSERT INTO poles_spatial \n",
    "            (pole_id, latitude, longitude, power_type, voltage, osm_source, geom)\n",
    "            VALUES (%s, %s, %s, %s, %s, TRUE, ST_SetSRID(ST_MakePoint(%s, %s), 4326))\n",
    "        \"\"\",\n",
    "        row_mapper=lambda r: (\n",
    "            str(r[0]), r[1], r[2], r[3], r[4],\n",
    "            r[2], r[1]  # lon, lat for geom\n",
    "        )\n",
    "    )\n",
    "\n",
    "def sync_vegetation():\n",
    "    \"\"\"Sync 3.6K vegetation risk records.\"\"\"\n",
    "    return sync_layer(\n",
    "        layer_name='vegetation',\n",
    "        sf_query=\"\"\"\n",
    "            SELECT TREE_ID, TREE_LAT, TREE_LON, NEAREST_POWER_LINE_ID, \n",
    "                   DISTANCE_TO_LINE_METERS, VEGETATION_RISK_LEVEL, RISK_SCORE\n",
    "            FROM VEGETATION_POWER_LINE_RISK\n",
    "            WHERE TREE_LAT IS NOT NULL AND TREE_LON IS NOT NULL\n",
    "        \"\"\",\n",
    "        pg_table='vegetation_risk_cache',\n",
    "        pg_insert_sql=\"\"\"\n",
    "            INSERT INTO vegetation_risk_cache \n",
    "            (tree_id, latitude, longitude, nearest_line_id, nearest_line_distance_m,\n",
    "             encroachment_category, risk_score, geom)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326))\n",
    "        \"\"\",\n",
    "        row_mapper=lambda r: (\n",
    "            r[0], r[1], r[2], r[3], r[4], r[5], r[6],\n",
    "            r[2], r[1]  # lon, lat for geom\n",
    "        )\n",
    "    )"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_power_lines():\n",
    "    \"\"\"Sync 13K power lines with LineString geometry.\"\"\"\n",
    "    result = SyncResult('power_lines')\n",
    "    \n",
    "    try:\n",
    "        sf_conn = get_snowflake_conn()\n",
    "        pg_conn = get_postgres_conn()\n",
    "        pg_cursor = pg_conn.cursor()\n",
    "        \n",
    "        print(\"Syncing power_lines...\")\n",
    "        pg_cursor.execute('TRUNCATE TABLE power_lines_lod;')\n",
    "        \n",
    "        sf_cursor = sf_conn.cursor()\n",
    "        sf_cursor.execute(\"\"\"\n",
    "            SELECT LINE_ID, CIRCUIT_ID, SUBSTATION_ID, LINE_TYPE, VOLTAGE_CLASS,\n",
    "                   LINE_LENGTH_M, ST_ASGEOJSON(GEOMETRY) as GEOMETRY_JSON\n",
    "            FROM GRID_POWER_LINES\n",
    "            WHERE GEOMETRY IS NOT NULL\n",
    "        \"\"\")\n",
    "        \n",
    "        count = 0\n",
    "        for row in sf_cursor:\n",
    "            line_id, circuit_id, sub_id, line_type, voltage, length_m, geojson = row\n",
    "            if geojson:\n",
    "                pg_cursor.execute(\"\"\"\n",
    "                    INSERT INTO power_lines_lod \n",
    "                    (line_id, circuit_id, substation_id, voltage_class, length_km, geom)\n",
    "                    VALUES (%s, %s, %s, %s, %s, ST_GeomFromGeoJSON(%s))\n",
    "                \"\"\", (line_id, circuit_id, sub_id, voltage, length_m/1000 if length_m else None, geojson))\n",
    "                count += 1\n",
    "        \n",
    "        sf_conn.close()\n",
    "        pg_conn.close()\n",
    "        return result.complete(count)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return result.fail(e)\n",
    "\n",
    "\n",
    "def sync_buildings():\n",
    "    \"\"\"Sync 2.6M building footprints.\"\"\"\n",
    "    result = SyncResult('buildings')\n",
    "    \n",
    "    try:\n",
    "        sf_conn = get_snowflake_conn()\n",
    "        pg_conn = get_postgres_conn()\n",
    "        pg_cursor = pg_conn.cursor()\n",
    "        \n",
    "        print(\"Syncing buildings (this may take several minutes)...\")\n",
    "        pg_cursor.execute('TRUNCATE TABLE osm_buildings;')\n",
    "        \n",
    "        sf_cursor = sf_conn.cursor()\n",
    "        sf_cursor.execute(\"\"\"\n",
    "            SELECT BUILDING_ID, BUILDING_NAME, BUILDING_TYPE, HEIGHT_METERS, NUM_FLOORS,\n",
    "                   LONGITUDE, LATITUDE\n",
    "            FROM HOUSTON_BUILDINGS_CLEAN\n",
    "            WHERE LATITUDE IS NOT NULL AND LONGITUDE IS NOT NULL\n",
    "        \"\"\")\n",
    "        \n",
    "        batch = []\n",
    "        count = 0\n",
    "        \n",
    "        for row in sf_cursor:\n",
    "            batch.append((row[0], row[1], row[2], row[3], row[4], row[5], row[6]))\n",
    "            \n",
    "            if len(batch) >= CONFIG['batch_size']:\n",
    "                pg_cursor.executemany(\"\"\"\n",
    "                    INSERT INTO osm_buildings \n",
    "                    (osm_id, name, building_type, height_m, levels, centroid)\n",
    "                    VALUES (%s, %s, %s, %s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326))\n",
    "                \"\"\", batch)\n",
    "                count += len(batch)\n",
    "                print(f\"  ... {count:,} rows\")\n",
    "                batch = []\n",
    "        \n",
    "        if batch:\n",
    "            pg_cursor.executemany(\"\"\"\n",
    "                INSERT INTO osm_buildings \n",
    "                (osm_id, name, building_type, height_m, levels, centroid)\n",
    "                VALUES (%s, %s, %s, %s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326))\n",
    "            \"\"\", batch)\n",
    "            count += len(batch)\n",
    "        \n",
    "        sf_conn.close()\n",
    "        pg_conn.close()\n",
    "        return result.complete(count)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return result.fail(e)\n",
    "\n",
    "\n",
    "def sync_water_bodies():\n",
    "    \"\"\"Sync 10K water body polygons.\"\"\"\n",
    "    result = SyncResult('water_bodies')\n",
    "    \n",
    "    try:\n",
    "        sf_conn = get_snowflake_conn()\n",
    "        pg_conn = get_postgres_conn()\n",
    "        pg_cursor = pg_conn.cursor()\n",
    "        \n",
    "        print(\"Syncing water_bodies...\")\n",
    "        pg_cursor.execute('TRUNCATE TABLE osm_water;')\n",
    "        \n",
    "        sf_cursor = sf_conn.cursor()\n",
    "        sf_cursor.execute(\"\"\"\n",
    "            SELECT ID, NAMES:primary::VARCHAR as NAME, ST_ASGEOJSON(GEOMETRY) as GEOMETRY_JSON\n",
    "            FROM HOUSTON_WATER_BODIES\n",
    "            WHERE GEOMETRY IS NOT NULL\n",
    "        \"\"\")\n",
    "        \n",
    "        count = 0\n",
    "        for row in sf_cursor:\n",
    "            water_id, name, geojson = row\n",
    "            if geojson:\n",
    "                pg_cursor.execute(\"\"\"\n",
    "                    INSERT INTO osm_water (osm_id, name, geom)\n",
    "                    VALUES (%s, %s, ST_Multi(ST_GeomFromGeoJSON(%s)))\n",
    "                \"\"\", (water_id, name, geojson))\n",
    "                count += 1\n",
    "        \n",
    "        sf_conn.close()\n",
    "        pg_conn.close()\n",
    "        return result.complete(count)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return result.fail(e)"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sync All Layers"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_all_layers():\n",
    "    \"\"\"Sync all layers in optimal order.\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"SNOWFLAKE TO POSTGRES FULL SYNC\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print()\n",
    "    \n",
    "    # Sync order: smaller tables first, large tables last\n",
    "    sync_functions = [\n",
    "        ('Substations', sync_substations),\n",
    "        ('Vegetation', sync_vegetation),\n",
    "        ('Water Bodies', sync_water_bodies),\n",
    "        ('Power Lines', sync_power_lines),\n",
    "        ('Poles', sync_poles),\n",
    "        ('Transformers', sync_transformers),\n",
    "        ('Meters', sync_meters),\n",
    "        ('Buildings', sync_buildings),\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    total_rows = 0\n",
    "    \n",
    "    for name, sync_fn in sync_functions:\n",
    "        print(f\"\\n--- {name} ---\")\n",
    "        result = sync_fn()\n",
    "        results.append(result)\n",
    "        print(result)\n",
    "        if result.status == 'success':\n",
    "            total_rows += result.rows\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SYNC SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    success = sum(1 for r in results if r.status == 'success')\n",
    "    failed = sum(1 for r in results if r.status == 'failed')\n",
    "    \n",
    "    for r in results:\n",
    "        print(r)\n",
    "    \n",
    "    print(f\"\\nTotal: {success} succeeded, {failed} failed\")\n",
    "    print(f\"Total rows synced: {total_rows:,}\")\n",
    "    print(f\"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment to run full sync:\n",
    "# results = sync_all_layers()"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sync Individual Layers\n",
    "\n",
    "Run individual sync operations as needed:"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync individual layers - uncomment as needed:\n",
    "\n",
    "# print(sync_substations())\n",
    "# print(sync_transformers())\n",
    "# print(sync_meters())\n",
    "# print(sync_poles())\n",
    "# print(sync_power_lines())\n",
    "# print(sync_buildings())\n",
    "# print(sync_water_bodies())\n",
    "# print(sync_vegetation())"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify Sync Results"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_sync():\n",
    "    \"\"\"Verify row counts in Postgres match expected values.\"\"\"\n",
    "    pg_conn = get_postgres_conn()\n",
    "    pg_cursor = pg_conn.cursor()\n",
    "    \n",
    "    tables = [\n",
    "        ('meters_spatial', 596906),\n",
    "        ('substations_spatial', 275),\n",
    "        ('transformers_spatial', 91554),\n",
    "        ('power_lines_lod', 13104),\n",
    "        ('poles_spatial', 62735),\n",
    "        ('osm_buildings', 2670794),\n",
    "        ('osm_water', 10000),\n",
    "        ('vegetation_risk_cache', 3611),\n",
    "    ]\n",
    "    \n",
    "    print(\"Postgres Table Row Counts\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for table, expected in tables:\n",
    "        pg_cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        actual = pg_cursor.fetchone()[0]\n",
    "        status = \"✓\" if actual > 0 else \"✗ EMPTY\"\n",
    "        pct = (actual / expected * 100) if expected > 0 else 0\n",
    "        print(f\"{status} {table:30} {actual:>10,} / {expected:>10,}  ({pct:.1f}%)\")\n",
    "    \n",
    "    pg_conn.close()\n",
    "\n",
    "verify_sync()"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Spatial Queries"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_spatial_queries():\n",
    "    \"\"\"Run sample spatial queries to verify PostGIS functionality.\"\"\"\n",
    "    pg_conn = get_postgres_conn()\n",
    "    pg_cursor = pg_conn.cursor()\n",
    "    \n",
    "    print(\"Testing Spatial Queries\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Test 1: Find transformers within 1km of a substation\n",
    "    pg_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM transformers_spatial t, substations_spatial s\n",
    "        WHERE ST_DWithin(t.geom::geography, s.geom::geography, 1000)\n",
    "        LIMIT 1\n",
    "    \"\"\")\n",
    "    print(f\"✓ Proximity query (transformers within 1km of substations): {pg_cursor.fetchone()[0]:,} pairs\")\n",
    "    \n",
    "    # Test 2: Find meters in a bounding box\n",
    "    pg_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM meters_spatial\n",
    "        WHERE geom && ST_MakeEnvelope(-95.5, 29.6, -95.3, 29.8, 4326)\n",
    "    \"\"\")\n",
    "    print(f\"✓ Bounding box query (meters in Houston center): {pg_cursor.fetchone()[0]:,} meters\")\n",
    "    \n",
    "    # Test 3: K-nearest neighbors\n",
    "    pg_cursor.execute(\"\"\"\n",
    "        SELECT transformer_id, ST_Distance(geom::geography, ST_SetSRID(ST_MakePoint(-95.4, 29.7), 4326)::geography) as dist_m\n",
    "        FROM transformers_spatial\n",
    "        ORDER BY geom <-> ST_SetSRID(ST_MakePoint(-95.4, 29.7), 4326)\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    print(f\"✓ K-nearest query (5 nearest transformers to downtown): {pg_cursor.fetchone()[0]}\")\n",
    "    \n",
    "    pg_conn.close()\n",
    "    print(\"\\nAll spatial queries working!\")\n",
    "\n",
    "test_spatial_queries()"
   ],
   "id": "cell-17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}