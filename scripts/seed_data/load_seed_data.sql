-- ============================================================================
-- FLUX OPS CENTER - SEED DATA LOADER
-- ============================================================================
-- This script loads production-quality seed data for the Flux Ops Center demo.
-- Run this after creating the database schema.
--
-- Prerequisites:
--   1. Create database: CREATE DATABASE FLUX_DEMO;
--   2. Create schema: CREATE SCHEMA FLUX_DEMO.PRODUCTION;
--   3. Upload parquet files to a stage (see instructions below)
--
-- Data Overview:
--   - Reference Data: Substations, circuits, transformers, poles, weather, ERCOT pricing
--   - Operational Data: Work orders, outages, PDF chunks for RAG
--   - Sample Data: 10K meters and their associated customers
--   - AMI Data: Generate using Flux Data Forge app (too large for Git)
-- ============================================================================

USE ROLE ACCOUNTADMIN;
USE WAREHOUSE COMPUTE_WH;

-- Create database and schema if not exists
CREATE DATABASE IF NOT EXISTS FLUX_DEMO;
CREATE SCHEMA IF NOT EXISTS FLUX_DEMO.PRODUCTION;
USE DATABASE FLUX_DEMO;
USE SCHEMA PRODUCTION;

-- ============================================================================
-- STEP 1: Create internal stage for seed data upload
-- ============================================================================
CREATE OR REPLACE STAGE SEED_DATA_STAGE
    FILE_FORMAT = (TYPE = PARQUET);

-- ============================================================================
-- STEP 2: Upload parquet files using Snow CLI
-- ============================================================================
-- Run these commands from your terminal (not in Snowflake):
--
-- snow stage copy scripts/seed_data/reference/ @FLUX_DEMO.PRODUCTION.SEED_DATA_STAGE/reference/ --recursive
-- snow stage copy scripts/seed_data/operational/ @FLUX_DEMO.PRODUCTION.SEED_DATA_STAGE/operational/ --recursive
-- snow stage copy scripts/seed_data/samples/ @FLUX_DEMO.PRODUCTION.SEED_DATA_STAGE/samples/ --recursive

-- ============================================================================
-- STEP 3: Create and load reference tables
-- ============================================================================

-- Substations (275 rows)
CREATE OR REPLACE TABLE SUBSTATIONS (
    SUBSTATION_ID VARCHAR,
    SUBSTATION_NAME VARCHAR,
    LATITUDE FLOAT,
    LONGITUDE FLOAT,
    CAPACITY_MW FLOAT,
    VOLTAGE_LEVEL_KV FLOAT,
    INSTALL_DATE DATE,
    STATUS VARCHAR,
    REGION VARCHAR
);

COPY INTO SUBSTATIONS
FROM @SEED_DATA_STAGE/reference/substations
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Circuit Metadata (8,842 rows)
CREATE OR REPLACE TABLE CIRCUIT_METADATA (
    CIRCUIT_ID VARCHAR,
    CIRCUIT_NAME VARCHAR,
    SUBSTATION_ID VARCHAR,
    VOLTAGE_CLASS VARCHAR,
    CIRCUIT_TYPE VARCHAR,
    TOTAL_CUSTOMERS NUMBER,
    TOTAL_TRANSFORMERS NUMBER,
    LINE_MILES FLOAT,
    INSTALL_DATE DATE,
    LATITUDE FLOAT,
    LONGITUDE FLOAT,
    STATUS VARCHAR
);

COPY INTO CIRCUIT_METADATA
FROM @SEED_DATA_STAGE/reference/circuit_metadata
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Transformer Metadata (91,554 rows)
CREATE OR REPLACE TABLE TRANSFORMER_METADATA (
    TRANSFORMER_ID VARCHAR,
    TRANSFORMER_NAME VARCHAR,
    CIRCUIT_ID VARCHAR,
    SUBSTATION_ID VARCHAR,
    KVA_RATING FLOAT,
    VOLTAGE_PRIMARY FLOAT,
    VOLTAGE_SECONDARY FLOAT,
    PHASE_CONFIG VARCHAR,
    INSTALL_DATE DATE,
    MANUFACTURER VARCHAR,
    LATITUDE FLOAT,
    LONGITUDE FLOAT,
    STATUS VARCHAR,
    LOAD_FACTOR FLOAT,
    LAST_MAINTENANCE_DATE DATE
);

COPY INTO TRANSFORMER_METADATA
FROM @SEED_DATA_STAGE/reference/transformer_metadata
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Grid Poles Infrastructure (62,038 rows)
CREATE OR REPLACE TABLE GRID_POLES_INFRASTRUCTURE (
    POLE_ID VARCHAR,
    POLE_TYPE VARCHAR,
    MATERIAL VARCHAR,
    HEIGHT_FT NUMBER,
    INSTALL_DATE DATE,
    CIRCUIT_ID VARCHAR,
    LATITUDE FLOAT,
    LONGITUDE FLOAT,
    CONDITION_STATUS VARCHAR,
    LAST_INSPECTION_DATE DATE
);

COPY INTO GRID_POLES_INFRASTRUCTURE
FROM @SEED_DATA_STAGE/reference/grid_poles_infrastructure
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Houston Weather Hourly (4,464 rows)
CREATE OR REPLACE TABLE HOUSTON_WEATHER_HOURLY (
    TIMESTAMP TIMESTAMP_NTZ,
    TEMPERATURE_F FLOAT,
    HUMIDITY_PCT FLOAT,
    WIND_SPEED_MPH FLOAT,
    PRECIPITATION_IN FLOAT,
    WEATHER_CONDITION VARCHAR,
    HEAT_INDEX FLOAT,
    WIND_CHILL FLOAT
);

COPY INTO HOUSTON_WEATHER_HOURLY
FROM @SEED_DATA_STAGE/reference/houston_weather_hourly
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- ERCOT LMP Houston Zone (45,213 rows)
CREATE OR REPLACE TABLE ERCOT_LMP_HOUSTON_ZONE (
    TIMESTAMP TIMESTAMP_NTZ,
    LMP_PRICE FLOAT,
    ENERGY_PRICE FLOAT,
    CONGESTION_PRICE FLOAT,
    LOSS_PRICE FLOAT,
    ZONE VARCHAR
);

COPY INTO ERCOT_LMP_HOUSTON_ZONE
FROM @SEED_DATA_STAGE/reference/ercot_lmp_houston_zone
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Power Quality Readings (10,000 rows)
CREATE OR REPLACE TABLE POWER_QUALITY_READINGS (
    READING_ID VARCHAR,
    METER_ID VARCHAR,
    TIMESTAMP TIMESTAMP_NTZ,
    VOLTAGE FLOAT,
    FREQUENCY FLOAT,
    THD_VOLTAGE FLOAT,
    THD_CURRENT FLOAT,
    POWER_FACTOR FLOAT,
    SAG_EVENT BOOLEAN,
    SWELL_EVENT BOOLEAN
);

COPY INTO POWER_QUALITY_READINGS
FROM @SEED_DATA_STAGE/reference/power_quality_readings
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- ============================================================================
-- STEP 4: Create and load operational tables
-- ============================================================================

-- SAP Work Orders (250,488 rows)
CREATE OR REPLACE TABLE SAP_WORK_ORDERS (
    WORK_ORDER_ID VARCHAR,
    WORK_ORDER_TYPE VARCHAR,
    PRIORITY VARCHAR,
    STATUS VARCHAR,
    CUSTOMER_ID VARCHAR,
    DESCRIPTION VARCHAR,
    CREATED_DATE TIMESTAMP_NTZ,
    SCHEDULED_DATE TIMESTAMP_NTZ,
    COMPLETED_DATE TIMESTAMP_NTZ,
    CREW_ID VARCHAR,
    ESTIMATED_DURATION_HOURS FLOAT,
    ACTUAL_DURATION_HOURS FLOAT,
    PARTS_COST FLOAT,
    LABOR_COST FLOAT
);

COPY INTO SAP_WORK_ORDERS
FROM @SEED_DATA_STAGE/operational/sap_work_orders
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Outage Events (34,252 rows)
CREATE OR REPLACE TABLE OUTAGE_EVENTS (
    OUTAGE_ID VARCHAR,
    TRANSFORMER_ID VARCHAR,
    CIRCUIT_ID VARCHAR,
    OUTAGE_START_TIME TIMESTAMP_NTZ,
    OUTAGE_END_TIME TIMESTAMP_NTZ,
    OUTAGE_CAUSE VARCHAR,
    CUSTOMERS_AFFECTED NUMBER,
    RESTORATION_CREW VARCHAR,
    WEATHER_RELATED BOOLEAN
);

COPY INTO OUTAGE_EVENTS
FROM @SEED_DATA_STAGE/operational/outage_events
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Technical Manuals PDF Chunks (20,000 rows) - for RAG
CREATE OR REPLACE TABLE TECHNICAL_MANUALS_PDF_CHUNKS (
    CHUNK_ID VARCHAR,
    DOCUMENT_NAME VARCHAR,
    CHUNK_INDEX NUMBER,
    CHUNK_TEXT VARCHAR,
    EMBEDDING VECTOR(FLOAT, 768)
);

COPY INTO TECHNICAL_MANUALS_PDF_CHUNKS (CHUNK_ID, DOCUMENT_NAME, CHUNK_INDEX, CHUNK_TEXT)
FROM @SEED_DATA_STAGE/operational/technical_manuals_pdf_chunks
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- ============================================================================
-- STEP 5: Create and load sample meter/customer data
-- ============================================================================

-- Meter Infrastructure (10,000 sample rows)
CREATE OR REPLACE TABLE METER_INFRASTRUCTURE (
    METER_ID VARCHAR,
    METER_LATITUDE FLOAT,
    METER_LONGITUDE FLOAT,
    COMMISSIONED_DATE DATE,
    METER_TYPE VARCHAR,
    CUSTOMER_SEGMENT_ID VARCHAR,
    POLE_ID VARCHAR,
    CIRCUIT_ID VARCHAR,
    TRANSFORMER_ID VARCHAR,
    SUBSTATION_ID VARCHAR,
    POLE_TYPE VARCHAR,
    POLE_MATERIAL VARCHAR,
    POLE_HEIGHT_FT NUMBER,
    CONDITION_STATUS VARCHAR,
    ZIP_CODE VARCHAR,
    LOCATION_COORDINATES VARCHAR,
    POLE_LATITUDE FLOAT,
    POLE_LONGITUDE FLOAT,
    CITY VARCHAR,
    COUNTY_NAME VARCHAR,
    LAST_UPDATED TIMESTAMP_NTZ,
    SNAPPED_TO_OSM_POLE_ID VARCHAR,
    OSM_POWER_TYPE VARCHAR,
    SNAP_DISTANCE_METERS FLOAT,
    ORIGINAL_SYNTHETIC_LAT FLOAT,
    ORIGINAL_SYNTHETIC_LON FLOAT,
    SNAPPED_AT TIMESTAMP_NTZ,
    IS_OFFSHORE_FACILITY BOOLEAN,
    DISTANCE_TO_BUILDING_METERS NUMBER,
    BUILDING_ID VARCHAR,
    ESTIMATED_SQFT NUMBER,
    PROPERTY_CATEGORY VARCHAR,
    BUILDING_TYPE VARCHAR,
    HEALTH_SCORE FLOAT
);

COPY INTO METER_INFRASTRUCTURE
FROM @SEED_DATA_STAGE/samples/meter_infrastructure_10k
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Customers Master Data (matching ~11,849 rows for sample meters)
CREATE OR REPLACE TABLE CUSTOMERS_MASTER_DATA (
    CUSTOMER_ID VARCHAR,
    FIRST_NAME VARCHAR,
    LAST_NAME VARCHAR,
    FULL_NAME VARCHAR,
    PRIMARY_METER_ID VARCHAR,
    CUSTOMER_SEGMENT VARCHAR,
    SERVICE_ADDRESS VARCHAR,
    SERVICE_COUNTY VARCHAR,
    PHONE VARCHAR,
    EMAIL VARCHAR,
    ACCOUNT_STATUS VARCHAR,
    SERVICE_START_DATE DATE,
    CREATED_AT TIMESTAMP_NTZ,
    DATA_SOURCE VARCHAR,
    ZIP_CODE NUMBER,
    CITY VARCHAR
);

COPY INTO CUSTOMERS_MASTER_DATA
FROM @SEED_DATA_STAGE/samples/customers_master_data_10k
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- ============================================================================
-- STEP 6: Create AMI Interval Readings table (populated by Flux Data Forge)
-- ============================================================================

CREATE OR REPLACE TABLE AMI_INTERVAL_READINGS (
    METER_ID VARCHAR,
    TIMESTAMP TIMESTAMP_NTZ,
    USAGE_KWH FLOAT,
    VOLTAGE NUMBER,
    POWER_FACTOR NUMBER(23,2),
    CUSTOMER_SEGMENT_ID VARCHAR,
    SOURCE_TABLE VARCHAR
);

-- ============================================================================
-- STEP 7: Verify data loads
-- ============================================================================
SELECT 'SUBSTATIONS' as table_name, COUNT(*) as row_count FROM SUBSTATIONS
UNION ALL SELECT 'CIRCUIT_METADATA', COUNT(*) FROM CIRCUIT_METADATA
UNION ALL SELECT 'TRANSFORMER_METADATA', COUNT(*) FROM TRANSFORMER_METADATA
UNION ALL SELECT 'GRID_POLES_INFRASTRUCTURE', COUNT(*) FROM GRID_POLES_INFRASTRUCTURE
UNION ALL SELECT 'HOUSTON_WEATHER_HOURLY', COUNT(*) FROM HOUSTON_WEATHER_HOURLY
UNION ALL SELECT 'ERCOT_LMP_HOUSTON_ZONE', COUNT(*) FROM ERCOT_LMP_HOUSTON_ZONE
UNION ALL SELECT 'POWER_QUALITY_READINGS', COUNT(*) FROM POWER_QUALITY_READINGS
UNION ALL SELECT 'SAP_WORK_ORDERS', COUNT(*) FROM SAP_WORK_ORDERS
UNION ALL SELECT 'OUTAGE_EVENTS', COUNT(*) FROM OUTAGE_EVENTS
UNION ALL SELECT 'TECHNICAL_MANUALS_PDF_CHUNKS', COUNT(*) FROM TECHNICAL_MANUALS_PDF_CHUNKS
UNION ALL SELECT 'METER_INFRASTRUCTURE', COUNT(*) FROM METER_INFRASTRUCTURE
UNION ALL SELECT 'CUSTOMERS_MASTER_DATA', COUNT(*) FROM CUSTOMERS_MASTER_DATA
UNION ALL SELECT 'AMI_INTERVAL_READINGS', COUNT(*) FROM AMI_INTERVAL_READINGS
ORDER BY table_name;

-- ============================================================================
-- NEXT STEPS:
-- 1. Run scripts/views/01_semantic_model_views.sql to create analytical views
-- 2. Run scripts/views/02_utility_views.sql to create utility views
-- 3. Deploy Flux Data Forge app to generate AMI readings
-- 4. Deploy Flux Ops Center app for the demo
-- ============================================================================
