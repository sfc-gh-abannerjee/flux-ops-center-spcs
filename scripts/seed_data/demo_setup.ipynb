{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLUX Ops Center - Demo Setup Notebook\n",
    "\n",
    "This notebook walks you through setting up the FLUX Ops Center demo in your own Snowflake account.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The FLUX Ops Center is a comprehensive utility operations demo featuring:\n",
    "- **596K+ meters** with realistic infrastructure topology\n",
    "- **Real-time AMI data** with 15-minute interval readings\n",
    "- **Work orders, outages, and power quality events**\n",
    "- **Cortex Analyst** semantic model for natural language queries\n",
    "- **Cortex Agent** for intelligent operations assistance\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Snowflake account with ACCOUNTADMIN access\n",
    "2. Python 3.8+ with required packages\n",
    "3. Clone of the flux-ops-center-spcs repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install snowflake-connector-python pandas pyarrow snowflake-snowpark-python --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "print(f\"Setup started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configure Snowflake Connection\n",
    "\n",
    "Update these variables with your Snowflake account details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Update these values\n",
    "SNOWFLAKE_ACCOUNT = \"your_account\"  # e.g., \"xy12345.us-east-1\"\n",
    "SNOWFLAKE_USER = \"your_username\"\n",
    "SNOWFLAKE_PASSWORD = \"your_password\"  # Or use authenticator='externalbrowser'\n",
    "SNOWFLAKE_ROLE = \"ACCOUNTADMIN\"\n",
    "SNOWFLAKE_WAREHOUSE = \"COMPUTE_WH\"\n",
    "\n",
    "# Target database/schema for the demo\n",
    "TARGET_DATABASE = \"FLUX_DEMO\"\n",
    "TARGET_SCHEMA = \"PRODUCTION\"\n",
    "\n",
    "# Path to seed data (relative to this notebook)\n",
    "SEED_DATA_DIR = Path(\".\")  # Assumes notebook is in scripts/seed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use named connection from ~/.snowflake/connections.toml\n",
    "# Uncomment the following to use a named connection instead:\n",
    "\n",
    "# CONNECTION_NAME = \"my_connection\"\n",
    "# conn = snowflake.connector.connect(connection_name=CONNECTION_NAME)\n",
    "\n",
    "# Standard connection\n",
    "conn = snowflake.connector.connect(\n",
    "    account=SNOWFLAKE_ACCOUNT,\n",
    "    user=SNOWFLAKE_USER,\n",
    "    password=SNOWFLAKE_PASSWORD,\n",
    "    role=SNOWFLAKE_ROLE,\n",
    "    warehouse=SNOWFLAKE_WAREHOUSE,\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "print(\"✅ Connected to Snowflake!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Database and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database and schema\n",
    "cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {TARGET_DATABASE}\")\n",
    "cursor.execute(f\"USE DATABASE {TARGET_DATABASE}\")\n",
    "cursor.execute(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_SCHEMA}\")\n",
    "cursor.execute(f\"USE SCHEMA {TARGET_SCHEMA}\")\n",
    "\n",
    "print(f\"✅ Created {TARGET_DATABASE}.{TARGET_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Tables\n",
    "\n",
    "Create all required tables for the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Tables\n",
    "tables_ddl = {\n",
    "    'SUBSTATIONS': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS SUBSTATIONS (\n",
    "            SUBSTATION_ID VARCHAR, SUBSTATION_NAME VARCHAR,\n",
    "            LATITUDE FLOAT, LONGITUDE FLOAT, CAPACITY_MW FLOAT,\n",
    "            VOLTAGE_LEVEL_KV FLOAT, INSTALL_DATE DATE, STATUS VARCHAR, REGION VARCHAR\n",
    "        )\n",
    "    \"\"\",\n",
    "    'CIRCUIT_METADATA': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS CIRCUIT_METADATA (\n",
    "            CIRCUIT_ID VARCHAR, CIRCUIT_NAME VARCHAR, SUBSTATION_ID VARCHAR,\n",
    "            VOLTAGE_CLASS VARCHAR, CIRCUIT_TYPE VARCHAR, TOTAL_CUSTOMERS NUMBER,\n",
    "            TOTAL_TRANSFORMERS NUMBER, LINE_MILES FLOAT, INSTALL_DATE DATE,\n",
    "            LATITUDE FLOAT, LONGITUDE FLOAT, STATUS VARCHAR\n",
    "        )\n",
    "    \"\"\",\n",
    "    'TRANSFORMER_METADATA': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS TRANSFORMER_METADATA (\n",
    "            TRANSFORMER_ID VARCHAR, TRANSFORMER_NAME VARCHAR, CIRCUIT_ID VARCHAR,\n",
    "            SUBSTATION_ID VARCHAR, KVA_RATING FLOAT, VOLTAGE_PRIMARY FLOAT,\n",
    "            VOLTAGE_SECONDARY FLOAT, PHASE_CONFIG VARCHAR, INSTALL_DATE DATE,\n",
    "            MANUFACTURER VARCHAR, LATITUDE FLOAT, LONGITUDE FLOAT, STATUS VARCHAR,\n",
    "            LOAD_FACTOR FLOAT, LAST_MAINTENANCE_DATE DATE\n",
    "        )\n",
    "    \"\"\",\n",
    "    'GRID_POLES_INFRASTRUCTURE': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS GRID_POLES_INFRASTRUCTURE (\n",
    "            POLE_ID VARCHAR, POLE_TYPE VARCHAR, MATERIAL VARCHAR, HEIGHT_FT NUMBER,\n",
    "            INSTALL_DATE DATE, CIRCUIT_ID VARCHAR, LATITUDE FLOAT, LONGITUDE FLOAT,\n",
    "            CONDITION_STATUS VARCHAR, LAST_INSPECTION_DATE DATE\n",
    "        )\n",
    "    \"\"\",\n",
    "    'HOUSTON_WEATHER_HOURLY': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS HOUSTON_WEATHER_HOURLY (\n",
    "            TIMESTAMP TIMESTAMP_NTZ, TEMPERATURE_F FLOAT, HUMIDITY_PCT FLOAT,\n",
    "            WIND_SPEED_MPH FLOAT, PRECIPITATION_IN FLOAT, WEATHER_CONDITION VARCHAR,\n",
    "            HEAT_INDEX FLOAT, WIND_CHILL FLOAT\n",
    "        )\n",
    "    \"\"\",\n",
    "    'ERCOT_LMP_HOUSTON_ZONE': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS ERCOT_LMP_HOUSTON_ZONE (\n",
    "            TIMESTAMP TIMESTAMP_NTZ, LMP_PRICE FLOAT, ENERGY_PRICE FLOAT,\n",
    "            CONGESTION_PRICE FLOAT, LOSS_PRICE FLOAT, ZONE VARCHAR\n",
    "        )\n",
    "    \"\"\",\n",
    "    'POWER_QUALITY_READINGS': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS POWER_QUALITY_READINGS (\n",
    "            READING_ID VARCHAR, METER_ID VARCHAR, TIMESTAMP TIMESTAMP_NTZ,\n",
    "            VOLTAGE FLOAT, FREQUENCY FLOAT, THD_VOLTAGE FLOAT, THD_CURRENT FLOAT,\n",
    "            POWER_FACTOR FLOAT, SAG_EVENT BOOLEAN, SWELL_EVENT BOOLEAN\n",
    "        )\n",
    "    \"\"\",\n",
    "    'SAP_WORK_ORDERS': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS SAP_WORK_ORDERS (\n",
    "            WORK_ORDER_ID VARCHAR, WORK_ORDER_TYPE VARCHAR, PRIORITY VARCHAR,\n",
    "            STATUS VARCHAR, CUSTOMER_ID VARCHAR, DESCRIPTION VARCHAR,\n",
    "            CREATED_DATE TIMESTAMP_NTZ, SCHEDULED_DATE TIMESTAMP_NTZ,\n",
    "            COMPLETED_DATE TIMESTAMP_NTZ, CREW_ID VARCHAR,\n",
    "            ESTIMATED_DURATION_HOURS FLOAT, ACTUAL_DURATION_HOURS FLOAT,\n",
    "            LABOR_COST FLOAT, PARTS_COST FLOAT\n",
    "        )\n",
    "    \"\"\",\n",
    "    'OUTAGE_EVENTS': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS OUTAGE_EVENTS (\n",
    "            OUTAGE_ID VARCHAR, TRANSFORMER_ID VARCHAR, CIRCUIT_ID VARCHAR,\n",
    "            OUTAGE_START_TIME TIMESTAMP_NTZ, OUTAGE_END_TIME TIMESTAMP_NTZ,\n",
    "            OUTAGE_CAUSE VARCHAR, CUSTOMERS_AFFECTED NUMBER,\n",
    "            WEATHER_RELATED BOOLEAN, RESTORATION_CREW VARCHAR\n",
    "        )\n",
    "    \"\"\",\n",
    "    'METER_INFRASTRUCTURE': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS METER_INFRASTRUCTURE (\n",
    "            METER_ID VARCHAR, METER_LATITUDE FLOAT, METER_LONGITUDE FLOAT,\n",
    "            COMMISSIONED_DATE DATE, METER_TYPE VARCHAR, CUSTOMER_SEGMENT_ID VARCHAR,\n",
    "            POLE_ID VARCHAR, CIRCUIT_ID VARCHAR, TRANSFORMER_ID VARCHAR,\n",
    "            SUBSTATION_ID VARCHAR, POLE_TYPE VARCHAR, POLE_MATERIAL VARCHAR,\n",
    "            POLE_HEIGHT_FT NUMBER, CONDITION_STATUS VARCHAR, ZIP_CODE VARCHAR,\n",
    "            CITY VARCHAR, COUNTY_NAME VARCHAR, HEALTH_SCORE FLOAT\n",
    "        )\n",
    "    \"\"\",\n",
    "    'CUSTOMERS_MASTER_DATA': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS CUSTOMERS_MASTER_DATA (\n",
    "            CUSTOMER_ID VARCHAR, FIRST_NAME VARCHAR, LAST_NAME VARCHAR,\n",
    "            FULL_NAME VARCHAR, PRIMARY_METER_ID VARCHAR, CUSTOMER_SEGMENT VARCHAR,\n",
    "            SERVICE_ADDRESS VARCHAR, SERVICE_COUNTY VARCHAR, PHONE VARCHAR,\n",
    "            EMAIL VARCHAR, ACCOUNT_STATUS VARCHAR, SERVICE_START_DATE DATE,\n",
    "            CREATED_AT TIMESTAMP_NTZ, DATA_SOURCE VARCHAR, ZIP_CODE NUMBER, CITY VARCHAR\n",
    "        )\n",
    "    \"\"\",\n",
    "    'AMI_INTERVAL_READINGS': \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS AMI_INTERVAL_READINGS (\n",
    "            METER_ID VARCHAR, TIMESTAMP TIMESTAMP_NTZ, USAGE_KWH FLOAT,\n",
    "            VOLTAGE NUMBER, POWER_FACTOR NUMBER(23,2),\n",
    "            CUSTOMER_SEGMENT_ID VARCHAR, SOURCE_TABLE VARCHAR\n",
    "        )\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "for table_name, ddl in tables_ddl.items():\n",
    "    cursor.execute(ddl)\n",
    "    print(f\"✅ Created: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Seed Data\n",
    "\n",
    "Load the parquet files into Snowflake tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet_to_table(table_name, parquet_pattern, subdir):\n",
    "    \"\"\"Load parquet files matching pattern into table.\"\"\"\n",
    "    parquet_dir = SEED_DATA_DIR / subdir\n",
    "    files = list(parquet_dir.glob(parquet_pattern))\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"⚠️  No files found for {table_name} ({parquet_pattern})\")\n",
    "        return 0\n",
    "    \n",
    "    total_rows = 0\n",
    "    for f in sorted(files):\n",
    "        df = pd.read_parquet(f)\n",
    "        success, _, _, _ = write_pandas(\n",
    "            conn=conn, df=df, table_name=table_name,\n",
    "            schema=TARGET_SCHEMA, quote_identifiers=False\n",
    "        )\n",
    "        if success:\n",
    "            total_rows += len(df)\n",
    "    \n",
    "    print(f\"✅ {table_name}: {total_rows:,} rows loaded\")\n",
    "    return total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Reference Data\n",
    "print(\"Loading Reference Data...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "load_parquet_to_table('SUBSTATIONS', 'substations*.parquet', 'reference')\n",
    "load_parquet_to_table('CIRCUIT_METADATA', 'circuit_metadata*.parquet', 'reference')\n",
    "load_parquet_to_table('TRANSFORMER_METADATA', 'transformer_metadata*.parquet', 'reference')\n",
    "load_parquet_to_table('GRID_POLES_INFRASTRUCTURE', 'grid_poles*.parquet', 'reference')\n",
    "load_parquet_to_table('HOUSTON_WEATHER_HOURLY', 'houston_weather*.parquet', 'reference')\n",
    "load_parquet_to_table('ERCOT_LMP_HOUSTON_ZONE', 'ercot_lmp*.parquet', 'reference')\n",
    "load_parquet_to_table('POWER_QUALITY_READINGS', 'power_quality*.parquet', 'reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Operational Data\n",
    "print(\"\\nLoading Operational Data...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "load_parquet_to_table('SAP_WORK_ORDERS', 'sap_work_orders*.parquet', 'operational')\n",
    "load_parquet_to_table('OUTAGE_EVENTS', 'outage_events*.parquet', 'operational')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sample Data (10K meters + customers)\n",
    "print(\"\\nLoading Sample Data...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "load_parquet_to_table('METER_INFRASTRUCTURE', 'meter_infrastructure_10k*.parquet', 'samples')\n",
    "load_parquet_to_table('CUSTOMERS_MASTER_DATA', 'customers_master_data_10k*.parquet', 'samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Data Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify row counts\n",
    "expected_counts = {\n",
    "    'SUBSTATIONS': 275,\n",
    "    'CIRCUIT_METADATA': 8842,\n",
    "    'TRANSFORMER_METADATA': 91554,\n",
    "    'GRID_POLES_INFRASTRUCTURE': 62038,\n",
    "    'HOUSTON_WEATHER_HOURLY': 4464,\n",
    "    'ERCOT_LMP_HOUSTON_ZONE': 45213,\n",
    "    'POWER_QUALITY_READINGS': 10000,\n",
    "    'SAP_WORK_ORDERS': 250488,\n",
    "    'OUTAGE_EVENTS': 34252,\n",
    "    'METER_INFRASTRUCTURE': 10000,\n",
    "    'CUSTOMERS_MASTER_DATA': 11849,\n",
    "}\n",
    "\n",
    "print(\"\\nVerifying Data Loads...\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Table':<35} {'Expected':>10} {'Actual':>10} {'Status':>8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for table, expected in expected_counts.items():\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "    actual = cursor.fetchone()[0]\n",
    "    status = \"✅\" if actual >= expected * 0.9 else \"⚠️\"\n",
    "    print(f\"{table:<35} {expected:>10,} {actual:>10,} {status:>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate AMI Readings (Optional)\n",
    "\n",
    "The AMI readings are too large to include in the repository. You have two options:\n",
    "\n",
    "1. **Deploy Flux Data Forge** - Generate realistic streaming AMI data\n",
    "2. **Generate sample data** - Use the code below for quick testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sample AMI data generation (for testing)\n",
    "import random\n",
    "from datetime import timedelta\n",
    "\n",
    "def generate_sample_ami(meters_df, days=7, interval_minutes=15):\n",
    "    \"\"\"Generate sample AMI readings for testing.\"\"\"\n",
    "    readings = []\n",
    "    start_date = datetime.now() - timedelta(days=days)\n",
    "    \n",
    "    meter_ids = meters_df['METER_ID'].tolist()[:100]  # Limit for quick testing\n",
    "    \n",
    "    for meter_id in meter_ids:\n",
    "        current_time = start_date\n",
    "        while current_time < datetime.now():\n",
    "            hour = current_time.hour\n",
    "            # Time-of-day usage pattern\n",
    "            if 14 <= hour <= 19:  # Peak\n",
    "                usage = random.uniform(1.5, 3.5)\n",
    "            elif 6 <= hour <= 9:  # Morning\n",
    "                usage = random.uniform(1.0, 2.5)\n",
    "            else:  # Off-peak\n",
    "                usage = random.uniform(0.3, 1.5)\n",
    "            \n",
    "            readings.append({\n",
    "                'METER_ID': meter_id,\n",
    "                'TIMESTAMP': current_time,\n",
    "                'USAGE_KWH': round(usage, 4),\n",
    "                'VOLTAGE': random.randint(118, 122),\n",
    "                'POWER_FACTOR': round(random.uniform(0.92, 0.99), 2),\n",
    "                'CUSTOMER_SEGMENT_ID': 'RESIDENTIAL',\n",
    "                'SOURCE_TABLE': 'GENERATED'\n",
    "            })\n",
    "            current_time += timedelta(minutes=interval_minutes)\n",
    "    \n",
    "    return pd.DataFrame(readings)\n",
    "\n",
    "# Uncomment to generate sample AMI data:\n",
    "# meters_df = pd.read_sql(\"SELECT METER_ID FROM METER_INFRASTRUCTURE LIMIT 100\", conn)\n",
    "# ami_df = generate_sample_ami(meters_df, days=7)\n",
    "# write_pandas(conn, ami_df, 'AMI_INTERVAL_READINGS', schema=TARGET_SCHEMA)\n",
    "# print(f\"Generated {len(ami_df):,} AMI readings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Views\n",
    "\n",
    "Run the view creation scripts from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to view scripts\n",
    "views_dir = SEED_DATA_DIR.parent / 'views'\n",
    "\n",
    "print(\"View scripts to run:\")\n",
    "print(f\"  1. {views_dir / '01_semantic_model_views.sql'}\")\n",
    "print(f\"  2. {views_dir / '02_utility_views.sql'}\")\n",
    "print(\"\\nRun these in Snowsight or using Snow CLI:\")\n",
    "print(f\"  snow sql -f {views_dir / '01_semantic_model_views.sql'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Your FLUX Ops Center demo environment is now set up with:\n",
    "\n",
    "| Data Type | Records | Description |\n",
    "|-----------|---------|-------------|\n",
    "| Substations | 275 | Grid substations |\n",
    "| Circuits | 8,842 | Distribution circuits |\n",
    "| Transformers | 91,554 | Distribution transformers |\n",
    "| Poles | 62,038 | Grid pole infrastructure |\n",
    "| Weather | 4,464 | Houston hourly weather |\n",
    "| ERCOT Pricing | 45,213 | LMP pricing data |\n",
    "| Work Orders | 250,488 | SAP-style maintenance |\n",
    "| Outages | 34,252 | Historical outage events |\n",
    "| Meters | 10,000 | Sample meter infrastructure |\n",
    "| Customers | ~12,000 | Associated customers |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Create Views**: Run the SQL scripts in `scripts/views/`\n",
    "2. **Deploy Flux Data Forge**: Generate real-time AMI data\n",
    "3. **Deploy Flux Ops Center**: Main demo application\n",
    "4. **Configure Cortex Analyst**: Set up semantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"\\n✅ Setup complete! Connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
